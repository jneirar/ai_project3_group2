{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "from os import getcwd, listdir\n",
    "from os.path import join\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Para descargar el dataset, ejecutar el siguiente fragmento de código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'url =  \\'https://drive.google.com/uc?id=1yh76NNJXhH71DonWlAoIvomYcNJ79bd3&export=download\\'\\noutput = \\'images.zip\\'\\ngdown.download(url, output, quiet=False)\\n\\npath = os.getcwd() + \"/\"\\npath += \"images.zip\"\\narchivo_zip = zipfile.ZipFile(path, \"r\")\\narchivo_zip.extractall()\\narchivo_zip.close()\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''url =  'https://drive.google.com/uc?id=1yh76NNJXhH71DonWlAoIvomYcNJ79bd3&export=download'\n",
    "output = 'images.zip'\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "path = os.getcwd() + \"/\"\n",
    "path += \"images.zip\"\n",
    "archivo_zip = zipfile.ZipFile(path, \"r\")\n",
    "archivo_zip.extractall()\n",
    "archivo_zip.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables y semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8365845167708341"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = getcwd()\n",
    "PATH_TO_DATASET = PATH + \"/images\"\n",
    "PATH_TO_ENCODES = PATH + \"/encodes\"\n",
    "random.seed(3589429)\n",
    "np.random.seed(3589429)\n",
    "np.random.rand()\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificador de imágenes:\n",
    "- Recibe las imágenes del dataset, las re-escala y procede a escribir sus *eigenvectors*.\n",
    "- También puede reducir aquellos *eigenvalues* que tengan una significancia menor a la deseada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder:   \n",
    "    def __init__(self):\n",
    "        self.data = listdir(PATH_TO_DATASET)\n",
    "        self.n = len(self.data)\n",
    "        self.compressions = 7\n",
    "        self.encodings = []\n",
    "        return\n",
    "\n",
    "    def __get_class(self,image):\n",
    "        image_class = int(image[:3])\n",
    "        return [int(x==image_class) for x in range(10)]\n",
    "\n",
    "    def encode_collection(self,iters=1,reduce_features=False,variance=0,resize_coef=128,debug=False):\n",
    "        train_size = int(self.n * 80 / 100)\n",
    "        validation_size = int(self.n * 10 / 100)\n",
    "        dim = 0\n",
    "        for iter in range(iters):\n",
    "            slices = self.__compute_slices([10,10])\n",
    "            encodings = []\n",
    "            classes = []\n",
    "            for _, slice in slices.items():\n",
    "                for i in slice:\n",
    "                    image = self.data[i]\n",
    "                    path_to_image = PATH_TO_DATASET + \"/\" + image\n",
    "                    image_class = self.__get_class(image)\n",
    "                    classes.append(image_class)\n",
    "                    image_code = Image.open(path_to_image)\n",
    "                    image_resized = np.array(image_code.resize((resize_coef, resize_coef)))\n",
    "                    image_resized = image_resized.flat\n",
    "                    image_encoding = pywt.wavedecn(data=image_resized,wavelet='haar',mode='symmetric',level=7)[0]\n",
    "                    dim = len(image_encoding)\n",
    "                    image_encoding = list(image_encoding)\n",
    "                    encodings.append(image_encoding)\n",
    "            if reduce_features == True:\n",
    "                pca = PCA(n_components=variance, svd_solver='full')\n",
    "                pca.fit(encodings)\n",
    "                transformed_encodings = pca.transform(encodings)\n",
    "                dim = transformed_encodings.shape[1]\n",
    "                encodings = []\n",
    "                for encode in transformed_encodings:\n",
    "                    encodings.append(encode.tolist())\n",
    "            \n",
    "            #Normalización:\n",
    "            encodings = np.array(encodings)\n",
    "            sc = MinMaxScaler()\n",
    "            sc.fit(encodings)\n",
    "            encodings = sc.transform(encodings)\n",
    "            encodings = encodings.tolist()\n",
    "            \n",
    "            collection = {\n",
    "                \"Train\": {\n",
    "                    \"Classes\": classes[:train_size],\n",
    "                    \"Images\": encodings[:train_size]\n",
    "                },\n",
    "                \"Validation\": { \n",
    "                    \"Classes\": classes[train_size:train_size+validation_size],\n",
    "                    \"Images\": encodings[train_size:train_size+validation_size]\n",
    "                },\n",
    "                \"Test\": {\n",
    "                    \"Classes\": classes[train_size+validation_size:],\n",
    "                    \"Images\": encodings[train_size+validation_size:]\n",
    "                }\n",
    "            }\n",
    "            with open(f\"{PATH_TO_ENCODES}/img_encodings_{iter+1}.json\", \"w\") as output:\n",
    "                output.truncate(0)\n",
    "                json.dump(collection, output, indent=4)\n",
    "                output.close()\n",
    "        if debug == True:\n",
    "            print(f\"[ImageEncoder]: Se redujeron {self.n} imagenes a {resize_coef}x{resize_coef}.\")\n",
    "            print(f\"[ImageEncoder]: Dichas reducciones, han sido escritas en {iters} colecciones.\")\n",
    "            print(f\"[ImageEncoder]: Las dimensiones finales son de {dim}.\")\n",
    "        return \n",
    "\n",
    "    def __compute_slices(self,slices):\n",
    "        idxs = [i for i in range(self.n)]\n",
    "        validation_size = int(self.n * slices[0] / 100)\n",
    "        test_size = int(self.n * slices[1] / 100)\n",
    "        rand_arr = random.sample(range(self.n), validation_size + test_size)\n",
    "        idxs = np.array(list(set(idxs) - set(rand_arr)))\n",
    "        slices = {\n",
    "            \"Train\": idxs, \n",
    "            \"Validation\": np.array(rand_arr[:validation_size]), \n",
    "            \"Test\": np.array(rand_arr[validation_size:])\n",
    "        }\n",
    "        return slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de los archivos json\n",
    "Usamos la clase *ImageEncoder* para generar los archivos json. Recordar que a menor valor de varianza, menos características del *dataset* original se mantendrán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ImageEncoder]: Se redujeron 832 imagenes a 128x128.\n",
      "[ImageEncoder]: Dichas reducciones, han sido escritas en 3 colecciones.\n",
      "[ImageEncoder]: Las dimensiones finales son de 49.\n"
     ]
    }
   ],
   "source": [
    "ie = ImageEncoder()\n",
    "ie.encode_collection(iters=3, reduce_features=True, variance=0.98, debug=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
