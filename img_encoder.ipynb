{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from PIL import Image\n",
    "from os import getcwd, listdir\n",
    "from os.path import join\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para descargar el dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'url =  \\'https://drive.google.com/uc?id=1yh76NNJXhH71DonWlAoIvomYcNJ79bd3&export=download\\'\\noutput = \\'images.zip\\'\\ngdown.download(url, output, quiet=False)\\n\\npath = os.getcwd() + \"/\"\\npath += \"images.zip\"\\narchivo_zip = zipfile.ZipFile(path, \"r\")\\narchivo_zip.extractall()\\narchivo_zip.close()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''url =  'https://drive.google.com/uc?id=1yh76NNJXhH71DonWlAoIvomYcNJ79bd3&export=download'\n",
    "output = 'images.zip'\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "path = os.getcwd() + \"/\"\n",
    "path += \"images.zip\"\n",
    "archivo_zip = zipfile.ZipFile(path, \"r\")\n",
    "archivo_zip.extractall()\n",
    "archivo_zip.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables y semilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8365845167708341"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = getcwd()\n",
    "PATH_TO_DATASET = PATH + \"/images\"\n",
    "PATH_TO_ENCODES = PATH + \"/encodes\"\n",
    "random.seed(3589429)\n",
    "np.random.seed(3589429)\n",
    "np.random.rand()\n",
    "random.random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codificador de imagenes:\n",
    "- Recibe las imagenes del dataset, las re-escala y procede a escribir sus eigenvectors\n",
    "- También puede reducir aquellos eigenvalues que tengan una significancia menor a la deseada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageEncoder:   \n",
    "    def __init__(self):\n",
    "        self.data = listdir(PATH_TO_DATASET)\n",
    "        self.n = len(self.data)\n",
    "        self.compressions = 7\n",
    "        self.encodings = []\n",
    "        return\n",
    "\n",
    "    def __get_class(self,image):\n",
    "        image_class = int(image[:3])\n",
    "        return [int(x==image_class) for x in range(10)]\n",
    "\n",
    "    def encode_collection(self,iters=1,reduce_features=False,variance=0,resize_coef=128,debug=False):\n",
    "        train_size = int(self.n * 80 / 100)\n",
    "        validation_size = int(self.n * 10 / 100)\n",
    "        dim = 0\n",
    "        for iter in range(iters):\n",
    "            slices = self.__compute_slices([10,10])\n",
    "            encodings = []\n",
    "            classes = []\n",
    "            for _, slice in slices.items():\n",
    "                for i in slice:\n",
    "                    image = self.data[i]\n",
    "                    path_to_image = PATH_TO_DATASET + \"/\" + image\n",
    "                    image_class = self.__get_class(image)\n",
    "                    classes.append(image_class)\n",
    "                    image_code = Image.open(path_to_image)\n",
    "                    image_resized = np.array(image_code.resize((resize_coef, resize_coef)))\n",
    "                    image_resized = image_resized.flat\n",
    "                    image_encoding = pywt.wavedecn(data=image_resized,wavelet='haar',mode='symmetric',level=7)[0]\n",
    "                    dim = len(image_encoding)\n",
    "                    image_encoding = list(image_encoding)\n",
    "                    encodings.append(image_encoding)\n",
    "            if reduce_features == True:\n",
    "                pca = PCA(n_components=variance, svd_solver='full')\n",
    "                pca.fit(encodings)\n",
    "                transformed_encodings = pca.transform(encodings)\n",
    "                dim = transformed_encodings.shape[1]\n",
    "                encodings = []\n",
    "                for encode in transformed_encodings:\n",
    "                    encodings.append(encode.tolist())\n",
    "            \n",
    "            #Normalización:\n",
    "            '''encodings = np.array(encodings)\n",
    "            sc = MinMaxScaler()\n",
    "            sc.fit(encodings)\n",
    "            encodings = sc.transform(encodings)\n",
    "            encodings = encodings.tolist()'''\n",
    "            \n",
    "            collection = {\n",
    "                \"Train\": {\n",
    "                    \"Classes\": classes[:train_size],\n",
    "                    \"Images\": encodings[:train_size]\n",
    "                },\n",
    "                \"Validation\": { \n",
    "                    \"Classes\": classes[train_size:train_size+validation_size],\n",
    "                    \"Images\": encodings[train_size:train_size+validation_size]\n",
    "                },\n",
    "                \"Test\": {\n",
    "                    \"Classes\": classes[train_size+validation_size:],\n",
    "                    \"Images\": encodings[train_size+validation_size:]\n",
    "                }\n",
    "            }\n",
    "            with open(f\"{PATH_TO_ENCODES}/img_encodings_{iter+1}.json\", \"w\") as output:\n",
    "                output.truncate(0)\n",
    "                json.dump(collection, output, indent=4)\n",
    "                output.close()\n",
    "        if debug == True:\n",
    "            print(f\"[ImageEncoder]: Se redujeron {self.n} imagenes a {resize_coef}x{resize_coef}.\")\n",
    "            print(f\"[ImageEncoder]: Dichas reducciones, han sido escritas en {iters} colecciones.\")\n",
    "            print(f\"[ImageEncoder]: Las dimensiones finales son de {dim}.\")\n",
    "        return \n",
    "\n",
    "    def __compute_slices(self,slices):\n",
    "        idxs = [i for i in range(self.n)]\n",
    "        validation_size = int(self.n * slices[0] / 100)\n",
    "        test_size = int(self.n * slices[1] / 100)\n",
    "        rand_arr = random.sample(range(self.n), validation_size + test_size)\n",
    "        idxs = np.array(list(set(idxs) - set(rand_arr)))\n",
    "        slices = {\n",
    "            \"Train\": idxs, \n",
    "            \"Validation\": np.array(rand_arr[:validation_size]), \n",
    "            \"Test\": np.array(rand_arr[validation_size:])\n",
    "        }\n",
    "        return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ImageEncoder]: Se redujeron 832 imagenes a 128x128.\n",
      "[ImageEncoder]: Dichas reducciones, han sido escritas en 1 colecciones.\n",
      "[ImageEncoder]: Las dimensiones finales son de 38.\n"
     ]
    }
   ],
   "source": [
    "ie = ImageEncoder()\n",
    "ie.encode_collection(iters=1, reduce_features=True, variance=0.97, debug=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
